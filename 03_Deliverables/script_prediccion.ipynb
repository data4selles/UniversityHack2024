{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34154528",
   "metadata": {},
   "source": [
    "# 2. CLEANSED LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "add0ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandasql as psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66449a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw = 'C:\\\\Users\\\\anton\\\\OneDrive\\\\Documentos\\\\GitHub\\\\UniversityHack2024\\\\01_Data\\\\01_Raw\\\\'\n",
    "path_cleansed = 'C:\\\\Users\\\\anton\\\\OneDrive\\\\Documentos\\\\GitHub\\\\UniversityHack2024\\\\01_Data\\\\02_Cleansed\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288d5215",
   "metadata": {},
   "source": [
    "## 2.1 OF 123456.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19369ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta Excel para OF 123456\n",
    "path_OF_01 = path_raw + 'OF 123456.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a95fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el contenido en un DataFrame\n",
    "df_OF_01 = pd.read_excel(path_OF_01)\n",
    "print(df_OF_01.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8056d706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La consulta convierte el campo Lote a entero eliminando las barras ('/'), y cambiamos el nombre de las demás columnas.\n",
    "consulta = \"\"\"\n",
    "    SELECT \n",
    "    CAST(REPLACE(`Lote`, '/', '') AS INTEGER) AS Lote, \n",
    "    Orden AS OF,\n",
    "    `Cantidad entregada` AS Cantidad_entregada\n",
    "\n",
    "    FROM df\n",
    "    \"\"\"\n",
    "# Ejecutamos la consulta\n",
    "df_OF_02 = psql.sqldf(consulta, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40133486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el resultado en un archivo Excel\n",
    "df_OF_02.to_excel(f'{path_cleansed}OF_123456.xlsx', index=False)\n",
    "\n",
    "# Mostrar el resultado\n",
    "display(df_OF_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c0b9a0",
   "metadata": {},
   "source": [
    "## 2.2 Fases producción.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5e70ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta Excel para Fases de producción\n",
    "path_fases_01 = path_raw + 'Fases producción.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc4bfa6",
   "metadata": {},
   "source": [
    "### 2.2.1 PREINÓCULO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66489ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo Excel y guardar el contenido en un DataFrame\n",
    "df_preinoculo_01 = pd.read_excel(path_fases_01, sheet_name = \"Preinóculo\")\n",
    "display(df_preinoculo_01.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f3be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos la columnas 'ph_línea 3' y 'turbidez_línea 3' a numérico y forzamos los valores no numéricos a NaN\n",
    "df_preinoculo_01['ph_línea 3'] = pd.to_numeric(df_preinoculo_01['ph_línea 3'], errors='coerce')\n",
    "df_preinoculo_01['turbidez_línea 3'] = pd.to_numeric(df_preinoculo_01['turbidez_línea 3'], errors='coerce')\n",
    "print(df_preinoculo_01.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54f2f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preinoculo_01.to_excel(f'{path_cleansed}Fases producción_Preinóculo.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444ec2b4",
   "metadata": {},
   "source": [
    "### 2.2.2 INÓCULO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e80ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo Excel y guardar el contenido en un DataFrame\n",
    "df_inoculo_01 = pd.read_excel(path_fases_01, sheet_name = \"Inóculo\")\n",
    "display(df_inoculo_01.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f645f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inoculo_01.to_excel(f'{path_cleansed}Fases producción_Inóculo.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c19c98",
   "metadata": {},
   "source": [
    "### 2.2.3 CULTIVO FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92e561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el archivo Excel y guardamos el contenido en un DataFrame\n",
    "df_cultivo_01 = pd.read_excel(path_fases_01, sheet_name = \"Cultivo final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fc656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La consulta convierte los campos Lote, Turbidez y Glucosa g/L a valores numéricos, manejando excepciones como NULL.\n",
    "consulta = \"\"\"\n",
    "    SELECT \n",
    "        CAST(Lote AS Integer) AS Lote,\n",
    "        Fecha,\n",
    "        CAST(NULLIF(Turbidez, '-') AS Float) AS Turbidez,\n",
    "        Viabilidad,\n",
    "        CASE\n",
    "            WHEN `Glucosa g/L` REGEXP '^[0-9]+\\\\.[0-9]+$' THEN CAST(`Glucosa g/L` AS Float)\n",
    "            ELSE NULL\n",
    "        END AS Glucosa\n",
    "    FROM df_cultivoIPC_01\n",
    "\"\"\"\n",
    "df_cultivo_02 = psql.sqldf(consulta, locals())\n",
    "\n",
    "# Cambiamos, con la librería pandas, el tipo de campo 'Fecha' a DATETIME porque la librería pandasql no tiene la función\n",
    "df_cultivo_02['Fecha'] = pd.to_datetime(df_cultivo_02['Fecha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e7d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el resultado en un archivo Excel\n",
    "df_cultivo_02.to_excel(f'{path_cleansed}Fases producción_Cultivo final.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baddb33f",
   "metadata": {},
   "source": [
    "## 2.3 Fases producción_test.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86ef4e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta Excel para Fases de producción_test\n",
    "path_cultivotest_01 = path_raw + 'Fases producción_test.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce12e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo Excel y guardar el contenido en un DataFrame\n",
    "df_cultivotest_01 = pd.read_excel(path_cultivotest_01)\n",
    "# Eliminar la columna 'Producto 2'\n",
    "df_cultivotest_02 = df_cultivotest_01.drop(columns=['Producto 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c7bdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cultivotest_02.to_excel(f'{path_cleansed}Fases producción_test_Cultivo final.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353c1982",
   "metadata": {},
   "source": [
    "## 2.4 Cinéticos IPC.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "becb96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta Excel para Cinéticos IPC\n",
    "path_IPC_01 = path_raw + 'Cinéticos IPC.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0bcbb5",
   "metadata": {},
   "source": [
    "### 2.4.1 INÓCULO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108cca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inoculoIPC_01 = pd.read_excel(path_IPC_01, sheet_name = 'Inóculos')\n",
    "print(df_inoculoIPC_01.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10de062",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inoculoIPC_01.to_excel(f'{path_cleansed}CineticosIPC_Inoculos.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafad70d",
   "metadata": {},
   "source": [
    "### 2.4.2 CULTIVO FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc7fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el archivo Excel y guardamos el contenido en un DataFrame\n",
    "df_cultivoIPC_01 = pd.read_excel(path_IPC_01, sheet_name='Cultivos finales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca4fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La consulta convierte los campos Lote, Turbidez y Glucosa g/L a valores numéricos, manejando excepciones como NULL.\n",
    "consulta = \"\"\"\n",
    "    SELECT \n",
    "        CAST(Lote AS Integer) AS Lote,\n",
    "        Fecha,\n",
    "        CAST(NULLIF(Turbidez, '-') AS Float) AS Turbidez,\n",
    "        Viabilidad,\n",
    "        CASE\n",
    "            WHEN `Glucosa g/L` REGEXP '^[0-9]+\\\\.[0-9]+$' THEN CAST(`Glucosa g/L` AS Float)\n",
    "            ELSE NULL\n",
    "        END AS Glucosa\n",
    "    FROM df_cultivoIPC_01\n",
    "\"\"\"\n",
    "df_cultivoIPC_02 = psql.sqldf(consulta, locals())\n",
    "\n",
    "# Cambiamos, con la librería pandas, el tipo de campo 'Fecha' a DATETIME porque la librería pandasql no tiene la función\n",
    "df_cultivoIPC_02['Fecha'] = pd.to_datetime(df_cultivoIPC_02['Fecha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4552abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el resultado en un archivo Excel\n",
    "df_cultivoIPC_02.to_excel(f'{path_cleansed}CineticosIPC_Cultivos.xlsx', index=False)\n",
    "\n",
    "# Mostrar el resultado\n",
    "display(df_cultivoIPC_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90130e53",
   "metadata": {},
   "source": [
    "### 2.4.3 CENTRIFUGACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed61d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_centIPC_01 = pd.read_excel(path_IPC_01, sheet_name = 'Centrifugación')\n",
    "print(df_centIPC_01.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1af719",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_centIPC_01.to_excel(f'{path_cleansed}CineticosIPC_Centrifugacion.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5691d7d5",
   "metadata": {},
   "source": [
    "## 2.5 Horas inicio fin centrífugas.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d42242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_horascentrifuga_01 = path_raw + 'Horas inicio fin centrífugas.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_horascentrifuga_01 = pd.read_excel(path_horascentrifuga_01)\n",
    "print(df_horascentrifuga_01.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_horascentrifuga_01.to_excel(f'{path_cleansed}Centrifugacion.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71789bfd",
   "metadata": {},
   "source": [
    "## 2.6 Biorreactores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea3434e",
   "metadata": {},
   "source": [
    "### 2.6.1 Grandes (13169, 13170, 14614, 14615, 14616, 14617)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f9753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntamos, en primer lugar, los Excel de los diferentes biorreactores grandes en un sólo Excel\n",
    "# A continuación, añadimos una columna con el ID de cada biorreactor\n",
    "path_biograndes_01 = path_raw + 'biorreactores_grandes.xlsx'\n",
    "\n",
    "df_biograndes_01 = pd.read_excel(path_biograndes_01)\n",
    "print(df_biograndes_01.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6f29b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos el tipo de columna 'DateTime' a tipo DateTime\n",
    "df_biograndes_01['DateTime'] = pd.to_datetime(df_biograndes_01['DateTime'])\n",
    "# Añadimos la columna con el ID de cada Biorreactor\n",
    "df_biograndes_01.columns = [col if col in ['DateTime', 'Numero_Biorreactor'] else col.split('.')[1] for col in df_biograndes_01.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e140b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biograndes_01.to_excel(f'{path_cleansed}biorreactores_grandes.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e4e392",
   "metadata": {},
   "source": [
    "### 2.6.2 Pequeños (13171, 13172, 14618)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19382729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetimos el proceso anterior con los biorreactores pequeños\n",
    "path_biopequenyos_01 = path_raw + 'biorreactores_pequeños.xlsx'\n",
    "\n",
    "df_biopequenyos_01 = pd.read_excel(path_biopequenyos_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "818e1b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos el tipo de columna 'DateTime' a tipo DateTime\n",
    "df_biopequenyos_01['DateTime'] = pd.to_datetime(df_biopequenyos_01['DateTime'])\n",
    "# Añadimos la columna con el ID de cada Biorreactor\n",
    "df_biopequenyos_01.columns = [col if col in ['DateTime', 'Numero_Biorreactor'] else col.split('.')[1] for col in df_biopequenyos_01.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17755fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biopequenyos_01.to_excel(f'{path_cleansed}biorreactores_pequeños.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed1aba4",
   "metadata": {},
   "source": [
    "## 2.7 Centrifugadoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9bbfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seguimos un proceso análogo al llevado a cabo con los biorreactores\n",
    "path_centrifugadoras_01 = path_raw + 'centrifugadoras.xlsx'\n",
    "\n",
    "df_centrifugadoras_01 = pd.read_excel(path_centrifugadoras_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5347db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos el tipo de columna 'DateTime' a tipo DateTime\n",
    "df_centrifugadoras_01['DateTime'] = pd.to_datetime(df_centrifugadoras_01['DateTime'])\n",
    "# Cambiamos el nombre de las columnas\n",
    "df_centrifugadoras_01 = df_centrifugadoras_01.rename(columns={'17825_D01919022.PV': 'velocidad_separación', '17825_D01916503.PV': 'presion_agua', '17825_D01916047.PV': 'contrapresion', '17825_D01906041.PV': 'caudal', '17825_D01780551.PV': 'apertura_valvula_agua', '17825_CTF0101.EN_Total': 'descargas_totales', '17825_CTF0101.EN_Parcial': 'descargas parciales'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935c1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_centrifugadoras_01.to_excel(f'{path_cleansed}centrifugadoras.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9090be75",
   "metadata": {},
   "source": [
    "## 2.8 Temperatura y humedades.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f880932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_temperatura_01 = path_raw + 'Temperaturas y humedades.xlsx'\n",
    "\n",
    "df_temperatura_01 = pd.read_excel(path_temperatura_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae084d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos el tipo de columna 'DateTime' a tipo DateTime\n",
    "df_temperatura_01['DateTime'] = pd.to_datetime(df_temperatura_01['DateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c365664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temperatura_01.to_excel(f'{path_cleansed}temperaturas_humedades.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f522e387",
   "metadata": {},
   "source": [
    "# 3. STRUCTURED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b9f29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandasql as psql\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aa4d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cleansed = 'C:\\\\Users\\\\anton\\\\OneDrive\\\\Documentos\\\\GitHub\\\\UniversityHack2024\\\\data\\\\02_cleansed\\\\'\n",
    "path_structured = 'C:\\\\Users\\\\anton\\\\OneDrive\\\\Documentos\\\\GitHub\\\\UniversityHack2024\\\\data\\\\03_structured\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ad120",
   "metadata": {},
   "source": [
    "## 3.1 PREINÓCULO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67a7736",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_preinoculo_02 = path_cleansed + 'Fases producción_Preinóculo.xlsx'\n",
    "\n",
    "df_preinoculo_02 = pd.read_excel(path_preinoculo_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d339de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos columna de tiempo en horas\n",
    "df_preinoculo_02['horas_totales_preinoculo'] = (df_preinoculo_02['Fecha/hora fin'] - df_preinoculo_02['Fecha/hora inicio']).dt.total_seconds() / 3600\n",
    "# eliminamos las fechas\n",
    "df_preinoculo_02 = df_preinoculo_02.drop(['Fecha/hora inicio', 'Fecha/hora fin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc81b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear listas para almacenar los pH y turbidez seleccionados\n",
    "ph_usados = []\n",
    "turbidez_usados = []\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame\n",
    "for i, row in df_preinoculo_02.iterrows():\n",
    "    # Crear un DataFrame temporal con los pH, turbidez y líneas utilizadas de esa fila\n",
    "    temp_df = pd.DataFrame({\n",
    "        'ph': [row['ph_línea 1'], row['ph_línea 2'], row['ph_línea 3']],\n",
    "        'turbidez': [row['turbidez_línea 1'], row['turbidez_línea 2'], row['turbidez_línea 3']],\n",
    "        'utilizada': [row['linea_utilizada_línea 1'], row['linea_utilizada_línea 2'], row['linea_utilizada_línea 3']]\n",
    "    })\n",
    "    \n",
    "    # Filtrar los tubos que se utilizan\n",
    "    tubos_usados = temp_df[temp_df['utilizada'] == 1]\n",
    "    \n",
    "    # Tomar los valores de pH y turbidez de los tubos utilizados\n",
    "    ph_usados.append(tubos_usados['ph'].values)\n",
    "    turbidez_usados.append(tubos_usados['turbidez'].values)\n",
    "\n",
    "# Agregar los valores seleccionados al DataFrame original\n",
    "df_preinoculo_02['ph_usado_1'] = [x[0] if len(x) > 0 else np.nan for x in ph_usados]\n",
    "df_preinoculo_02['ph_usado_2'] = [x[1] if len(x) > 1 else np.nan for x in ph_usados]\n",
    "df_preinoculo_02['turbidez_usada_1'] = [x[0] if len(x) > 0 else np.nan for x in turbidez_usados]\n",
    "df_preinoculo_02['turbidez_usada_2'] = [x[1] if len(x) > 1 else np.nan for x in turbidez_usados]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cfa759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preinoculo_03 = df_preinoculo_02.drop(['ph_línea 1', 'ph_línea 2', 'ph_línea 3', 'turbidez_línea 1', 'turbidez_línea 2', 'turbidez_línea 3', 'linea_utilizada_línea 1', 'linea_utilizada_línea 2', 'linea_utilizada_línea 3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5d60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preinoculo_03.to_excel(f'{path_structured}preinoculo_total.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be6fab",
   "metadata": {},
   "source": [
    "## 3.2 INÓCULO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa7497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_inoculoIPC_02 = path_cleansed + 'CineticosIPC_Inoculos.xlsx'\n",
    "path_inoculo_02 = path_cleansed + 'Fases producción_Inóculo.xlsx'\n",
    "path_biopequenyos_02 = path_cleansed + 'biorreactores_pequeños.xlsx'\n",
    "\n",
    "df_inoculoIPC_02 = pd.read_excel(path_inoculoIPC_02)\n",
    "df_inoculo_02 = pd.read_excel(path_inoculo_02)\n",
    "df_biopequenyos_02 = pd.read_excel(path_biopequenyos_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284e121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = df_inoculoIPC_02.groupby('Lote').agg({\n",
    "    'Turbidez': ['mean', 'std', 'min', 'max'],\n",
    "    'Viabilidad': ['mean', 'std', 'min', 'max']\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e82e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renombramos columnas\n",
    "df_agrupado.columns = ['_'.join(col).strip() for col in df_agrupado.columns.values]\n",
    "df_agrupado = df_agrupado.rename(columns={'Lote_': 'LOTE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d9b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_inoculo_02, df_agrupado, on='LOTE', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0fb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pysqldf = lambda q: psql(q, globals())\n",
    "\n",
    "query = '''\n",
    "    SELECT\n",
    "        l.\"LOTE\",\n",
    "        AVG(b.Agitation_PV) AS avg_Agitation_PV,\n",
    "        MIN(b.Agitation_PV) AS min_Agitation_PV,\n",
    "        MAX(b.Agitation_PV) AS max_Agitation_PV,\n",
    "\n",
    "        AVG(b.Air_Sparge_PV) AS avg_Air_Sparge_PV,\n",
    "        MIN(b.Air_Sparge_PV) AS min_Air_Sparge_PV,\n",
    "        MAX(b.Air_Sparge_PV) AS max_Air_Sparge_PV,\n",
    "        \n",
    "        AVG(b.Biocontainer_Pressure_PV) AS avg_Biocontainer_Pressure_PV,\n",
    "        MIN(b.Biocontainer_Pressure_PV) AS min_Biocontainer_Pressure_PV,\n",
    "        MAX(b.Biocontainer_Pressure_PV) AS max_Biocontainer_Pressure_PV,\n",
    "\n",
    "        AVG(b.DO_1_PV) AS avg_DO_1_PV,\n",
    "        MIN(b.DO_1_PV) AS min_DO_1_PV,\n",
    "        MAX(b.DO_1_PV) AS max_DO_1_PV,\n",
    "\n",
    "        AVG(b.DO_2_PV) AS avg_DO_2_PV,\n",
    "        MIN(b.DO_2_PV) AS min_DO_2_PV,\n",
    "        MAX(b.DO_2_PV) AS max_DO_2_PV,\n",
    "\n",
    "        AVG(b.Gas_Overlay_PV) AS avg_Gas_Overlay_PV,\n",
    "        MIN(b.Gas_Overlay_PV) AS min_Gas_Overlay_PV,\n",
    "        MAX(b.Gas_Overlay_PV) AS max_Gas_Overlay_PV,\n",
    "\n",
    "        AVG(b.Load_Cell_Net_PV) AS avg_Load_Cell_Net_PV,\n",
    "        MIN(b.Load_Cell_Net_PV) AS min_Load_Cell_Net_PV,\n",
    "        MAX(b.Load_Cell_Net_PV) AS max_Load_Cell_Net_PV,\n",
    "\n",
    "        AVG(b.pH_1_PV) AS avg_pH_1_PV,\n",
    "        MIN(b.pH_1_PV) AS min_pH_1_PV,\n",
    "        MAX(b.pH_1_PV) AS max_pH_1_PV,\n",
    "\n",
    "        AVG(b.pH_2_PV) AS avg_pH_2_PV,\n",
    "        MIN(b.pH_2_PV) AS min_pH_2_PV,\n",
    "        MAX(b.pH_2_PV) AS max_pH_2_PV,\n",
    "\n",
    "        AVG(b.PUMP_1_PV) AS avg_PUMP_1_PV,\n",
    "        MIN(b.PUMP_1_PV) AS min_PUMP_1_PV,\n",
    "        MAX(b.PUMP_1_PV) AS max_PUMP_1_PV,\n",
    "\n",
    "        AVG(b.PUMP_1_TOTAL) AS avg_PUMP_1_TOTAL,\n",
    "        MIN(b.PUMP_1_TOTAL) AS min_PUMP_1_TOTAL,\n",
    "        MAX(b.PUMP_1_TOTAL) AS max_PUMP_1_TOTAL,\n",
    "\n",
    "        AVG(b.PUMP_2_PV) AS avg_PUMP_2_PV,\n",
    "        MIN(b.PUMP_2_PV) AS min_PUMP_2_PV,\n",
    "        MAX(b.PUMP_2_PV) AS max_PUMP_2_PV,\n",
    "\n",
    "        AVG(b.PUMP_2_TOTAL) AS avg_PUMP_2_TOTAL,\n",
    "        MIN(b.PUMP_2_TOTAL) AS min_PUMP_2_TOTAL,\n",
    "        MAX(b.PUMP_2_TOTAL) AS max_PUMP_2_TOTAL,\n",
    "\n",
    "        AVG(b.Single_Use_DO_PV) AS avg_Single_Use_DO_PV,\n",
    "        MIN(b.Single_Use_DO_PV) AS min_Single_Use_DO_PV,\n",
    "        MAX(b.Single_Use_DO_PV) AS max_Single_Use_DO_PV,\n",
    "\n",
    "        AVG(b.Single_Use_pH_PV) AS avg_Single_Use_pH_PV,\n",
    "        MIN(b.Single_Use_pH_PV) AS min_Single_Use_pH_PV,\n",
    "        MAX(b.Single_Use_pH_PV) AS max_Single_Use_pH_PV,\n",
    "\n",
    "        AVG(b.Temperatura_PV) AS avg_Temperatura_PV,\n",
    "        MIN(b.Temperatura_PV) AS min_Temperatura_PV,\n",
    "        MAX(b.Temperatura_PV) AS max_Temperatura_PV\n",
    "    FROM\n",
    "        df_final l\n",
    "    LEFT JOIN\n",
    "        df_biopequenyos_02 b\n",
    "    ON\n",
    "        l.\"ID bioreactor\" = b.Numero_Biorreactor\n",
    "        AND b.DateTime BETWEEN l.\"Fecha/hora inicio\" AND l.\"Fecha/hora fin\"\n",
    "    GROUP BY\n",
    "        l.\"LOTE\";\n",
    "'''\n",
    "\n",
    "resultado = pysqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "consulta = \"\"\"\n",
    "    SELECT *\n",
    "    FROM df_final\n",
    "    LEFT JOIN resultado\n",
    "    ON df_final.LOTE = resultado.LOTE\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadofinal = psql.sqldf(consulta, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f29e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadofinal.drop(columns=['LOTE.1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d7f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadofinal['horas_totales_inoculo'] = (resultadofinal['Fecha/hora fin'] - resultadofinal['Fecha/hora inicio']).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a390572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadofinal = resultadofinal.drop(['Fecha/hora inicio', 'Fecha/hora fin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d6e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadofinal.to_excel(f'{path_cleansed}inoculo_total.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1bbe23",
   "metadata": {},
   "source": [
    "## 3.3 CULTIVO FINAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "586d6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo Excel y guardar el contenido en un DataFrame\n",
    "path_cultivo_02 = path_cleansed + 'Fases producción_Cultivo final.xlsx'\n",
    "path_biograndes_02 = path_cleansed + 'biorreactores_grandes.xlsx'\n",
    "path_cultivoIPC_02 = path_cleansed + 'CineticosIPC_Cultivos.xlsx'\n",
    "\n",
    "df_cultivo_02 = pd.read_excel(path_cultivo_02)\n",
    "df_biograndes_02 = pd.read_excel(path_biograndes_02)\n",
    "df_cultivoIPC_02 = pd.read_excel(path_cultivoIPC_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fdbfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_cultivo_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9948e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "    SELECT\n",
    "        l.*,\n",
    "        AVG(b.Agitation_PV) AS avg_Agitation_PV,\n",
    "        MIN(b.Agitation_PV) AS min_Agitation_PV,\n",
    "        MAX(b.Agitation_PV) AS max_Agitation_PV,\n",
    "\n",
    "        AVG(b.Air_Sparge_PV) AS avg_Air_Sparge_PV,\n",
    "        MIN(b.Air_Sparge_PV) AS min_Air_Sparge_PV,\n",
    "        MAX(b.Air_Sparge_PV) AS max_Air_Sparge_PV,\n",
    "\n",
    "        AVG(b.Biocontainer_Pressure_PV) AS avg_Biocontainer_Pressure_PV,\n",
    "        MIN(b.Biocontainer_Pressure_PV) AS min_Biocontainer_Pressure_PV,\n",
    "        MAX(b.Biocontainer_Pressure_PV) AS max_Biocontainer_Pressure_PV,\n",
    "\n",
    "        AVG(b.DO_1_PV) AS avg_DO_1_PV,\n",
    "        MIN(b.DO_1_PV) AS min_DO_1_PV,\n",
    "        MAX(b.DO_1_PV) AS max_DO_1_PV,\n",
    "\n",
    "        AVG(b.DO_2_PV) AS avg_DO_2_PV,\n",
    "        MIN(b.DO_2_PV) AS min_DO_2_PV,\n",
    "        MAX(b.DO_2_PV) AS max_DO_2_PV,\n",
    "\n",
    "        AVG(b.Gas_Overlay_PV) AS avg_Gas_Overlay_PV,\n",
    "        MIN(b.Gas_Overlay_PV) AS min_Gas_Overlay_PV,\n",
    "        MAX(b.Gas_Overlay_PV) AS max_Gas_Overlay_PV,\n",
    "\n",
    "        AVG(b.Load_Cell_Net_PV) AS avg_Load_Cell_Net_PV,\n",
    "        MIN(b.Load_Cell_Net_PV) AS min_Load_Cell_Net_PV,\n",
    "        MAX(b.Load_Cell_Net_PV) AS max_Load_Cell_Net_PV,\n",
    "\n",
    "        AVG(b.pH_1_PV) AS avg_pH_1_PV,\n",
    "        MIN(b.pH_1_PV) AS min_pH_1_PV,\n",
    "        MAX(b.pH_1_PV) AS max_pH_1_PV,\n",
    "\n",
    "        AVG(b.pH_2_PV) AS avg_pH_2_PV,\n",
    "        MIN(b.pH_2_PV) AS min_pH_2_PV,\n",
    "        MAX(b.pH_2_PV) AS max_pH_2_PV,\n",
    "\n",
    "        AVG(b.PUMP_1_PV) AS avg_PUMP_1_PV,\n",
    "        MIN(b.PUMP_1_PV) AS min_PUMP_1_PV,\n",
    "        MAX(b.PUMP_1_PV) AS max_PUMP_1_PV,\n",
    "\n",
    "        AVG(b.PUMP_1_TOTAL) AS avg_PUMP_1_TOTAL,\n",
    "        MIN(b.PUMP_1_TOTAL) AS min_PUMP_1_TOTAL,\n",
    "        MAX(b.PUMP_1_TOTAL) AS max_PUMP_1_TOTAL,\n",
    "\n",
    "        AVG(b.PUMP_2_PV) AS avg_PUMP_2_PV,\n",
    "        MIN(b.PUMP_2_PV) AS min_PUMP_2_PV,\n",
    "        MAX(b.PUMP_2_PV) AS max_PUMP_2_PV,\n",
    "\n",
    "        AVG(b.PUMP_2_TOTAL) AS avg_PUMP_2_TOTAL,\n",
    "        MIN(b.PUMP_2_TOTAL) AS min_PUMP_2_TOTAL,\n",
    "        MAX(b.PUMP_2_TOTAL) AS max_PUMP_2_TOTAL,\n",
    "\n",
    "        AVG(b.Single_Use_DO_PV) AS avg_Single_Use_DO_PV,\n",
    "        MIN(b.Single_Use_DO_PV) AS min_Single_Use_DO_PV,\n",
    "        MAX(b.Single_Use_DO_PV) AS max_Single_Use_DO_PV,\n",
    "\n",
    "        AVG(b.Single_Use_pH_PV) AS avg_Single_Use_pH_PV,\n",
    "        MIN(b.Single_Use_pH_PV) AS min_Single_Use_pH_PV,\n",
    "        MAX(b.Single_Use_pH_PV) AS max_Single_Use_pH_PV,\n",
    "\n",
    "        AVG(b.Temperatura_PV) AS avg_Temperatura_PV,\n",
    "        MIN(b.Temperatura_PV) AS min_Temperatura_PV,\n",
    "        MAX(b.Temperatura_PV) AS max_Temperatura_PV\n",
    "    FROM\n",
    "        df_cultivo_02 l\n",
    "    LEFT JOIN\n",
    "        df_biograndes_02 b\n",
    "    ON\n",
    "        l.\"ID Bioreactor\" = b.Numero_Biorreactor\n",
    "        AND b.DateTime BETWEEN l.\"Fecha/hora inicio\" AND l.\"Fecha/hora fin\"\n",
    "    GROUP BY\n",
    "        l.\"LOTE\";\n",
    "'''\n",
    "\n",
    "# Ejecutar la consulta\n",
    "df_bio_metrics = psql.sqldf(query, locals())\n",
    "\n",
    "# Ver el resultado\n",
    "display(df_bio_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b84804dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los campos de fecha de object a datetime\n",
    "df_bio_metrics['Fecha/hora inicio'] = pd.to_datetime(df_bio_metrics['Fecha/hora inicio'])\n",
    "df_bio_metrics['Fecha/hora fin'] = pd.to_datetime(df_bio_metrics['Fecha/hora fin'])\n",
    "\n",
    "# Calculamos la diferencia entre las fechas\n",
    "df_bio_metrics['horas_totales_cultivofinal'] = (df_bio_metrics['Fecha/hora fin'] - df_bio_metrics['Fecha/hora inicio']).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "036a465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREAMOS UN DATAFRAME CON MÉTRICAS DE LAS DISTINTAS COLUMNAS DE CINÉTICOS IPC SEGÚN EL LOTE (MEDIA, MIN,...)\n",
    "df_metricsIPC = df_cultivoIPC_02.groupby('Lote').agg({\n",
    "    'Turbidez': ['mean', 'std', 'min', 'max'],\n",
    "    'Viabilidad': ['mean', 'std', 'min', 'max'],\n",
    "    'Glucosa': ['mean', 'std', 'min', 'max']\n",
    "}).reset_index()\n",
    "df_metricsIPC.columns = [''.join(col).strip() for col in df_metricsIPC.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b6aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT \n",
    "    b.LOTE,\n",
    "    `Orden en el encadenado` AS Orden,\n",
    "    `LOTE parental` AS LOTE_parental,\n",
    "    `ID Bioreactor` AS ID_Bioreactor,\n",
    "    horas_totales_cultivofinal,\n",
    "    `Volumen de inóculo utilizado` AS Volumen_inoculo_utilizado,\n",
    "    `Turbidez inicio cultivo` AS Turbidez_inicio_cultivo,\n",
    "    `Turbidez fin cultivo` AS Turbidez_fin_cultivo,\n",
    "    `Viabilidad final cultivo` AS Viabilidad_final_cultivo,\n",
    "    `ID Centrífuga` AS ID_Centrifuga,\n",
    "    `Centrifugación 1 turbidez` AS Centrifugacion_1_turbidez,\n",
    "    `Centrifugación 2 turbidez` AS Centrifugacion_2_turbidez,\n",
    "    `Producto 1` AS Producto_1,\n",
    "    avg_Agitation_PV AS Biorreactor_grande_avg_Agitation_PV,\n",
    "    min_Agitation_PV AS Biorreactor_grande_min_Agitation_PV,\n",
    "    max_Agitation_PV AS Biorreactor_grande_max_Agitation_PV,\n",
    "    avg_Air_Sparge_PV AS Biorreactor_grande_avg_Air_Sparge_PV,\n",
    "    min_Air_Sparge_PV AS Biorreactor_grande_min_Air_Sparge_PV,\n",
    "    max_Air_Sparge_PV AS Biorreactor_grande_max_Air_Sparge_PV,\n",
    "    avg_Biocontainer_Pressure_PV AS Biorreactor_grande_avg_Biocontainer_Pressure_PV,\n",
    "    min_Biocontainer_Pressure_PV AS Biorreactor_grande_min_Biocontainer_Pressure_PV,\n",
    "    max_Biocontainer_Pressure_PV AS Biorreactor_grande_max_Biocontainer_Pressure_PV,\n",
    "    avg_DO_1_PV AS Biorreactor_grande_avg_DO_1_PV,\n",
    "    min_DO_1_PV AS Biorreactor_grande_min_DO_1_PV,\n",
    "    max_DO_1_PV AS Biorreactor_grande_max_DO_1_PV,\n",
    "    avg_DO_2_PV AS Biorreactor_grande_avg_DO_2_PV,\n",
    "    min_DO_2_PV AS Biorreactor_grande_min_DO_2_PV,\n",
    "    max_DO_2_PV AS Biorreactor_grande_max_DO_2_PV,\n",
    "    avg_Gas_Overlay_PV AS Biorreactor_grande_avg_Gas_Overlay_PV,\n",
    "    min_Gas_Overlay_PV AS Biorreactor_grande_min_Gas_Overlay_PV,\n",
    "    max_Gas_Overlay_PV AS Biorreactor_grande_max_Gas_Overlay_PV,\n",
    "    avg_Load_Cell_Net_PV AS Biorreactor_grande_avg_Load_Cell_Net_PV,\n",
    "    min_Load_Cell_Net_PV AS Biorreactor_grande_min_Load_Cell_Net_PV,\n",
    "    max_Load_Cell_Net_PV AS Biorreactor_grande_max_Load_Cell_Net_PV,\n",
    "    avg_pH_1_PV AS Biorreactor_grande_avg_pH_1_PV,\n",
    "    min_pH_1_PV AS Biorreactor_grande_min_pH_1_PV,\n",
    "    max_pH_1_PV AS Biorreactor_grande_max_pH_1_PV,\n",
    "    avg_pH_2_PV AS Biorreactor_grande_avg_pH_2_PV,\n",
    "    min_pH_2_PV AS Biorreactor_grande_min_pH_2_PV,\n",
    "    max_pH_2_PV AS Biorreactor_grande_max_pH_2_PV,\n",
    "    avg_PUMP_1_PV AS Biorreactor_grande_avg_PUMP_1_PV,\n",
    "    min_PUMP_1_PV AS Biorreactor_grande_min_PUMP_1_PV,\n",
    "    max_PUMP_1_PV AS Biorreactor_grande_max_PUMP_1_PV,\n",
    "    avg_PUMP_1_TOTAL AS Biorreactor_grande_avg_PUMP_1_TOTAL,\n",
    "    min_PUMP_1_TOTAL AS Biorreactor_grande_min_PUMP_1_TOTAL,\n",
    "    max_PUMP_1_TOTAL AS Biorreactor_grande_max_PUMP_1_TOTAL,\n",
    "    avg_PUMP_2_PV AS Biorreactor_grande_avg_PUMP_2_PV,\n",
    "    min_PUMP_2_PV AS Biorreactor_grande_min_PUMP_2_PV,\n",
    "    max_PUMP_2_PV AS Biorreactor_grande_max_PUMP_2_PV,\n",
    "    avg_PUMP_2_TOTAL AS Biorreactor_grande_avg_PUMP_2_TOTAL,\n",
    "    min_PUMP_2_TOTAL AS Biorreactor_grande_min_PUMP_2_TOTAL,\n",
    "    max_PUMP_2_TOTAL AS Biorreactor_grande_max_PUMP_2_TOTAL,\n",
    "    avg_Single_Use_DO_PV AS Biorreactor_grande_avg_Single_Use_DO_PV,\n",
    "    min_Single_Use_DO_PV AS Biorreactor_grande_min_Single_Use_DO_PV,\n",
    "    max_Single_Use_DO_PV AS Biorreactor_grande_max_Single_Use_DO_PV,\n",
    "    avg_Single_Use_pH_PV AS Biorreactor_grande_avg_Single_Use_pH_PV,\n",
    "    min_Single_Use_pH_PV AS Biorreactor_grande_min_Single_Use_pH_PV,\n",
    "    max_Single_Use_pH_PV AS Biorreactor_grande_max_Single_Use_pH_PV,\n",
    "    avg_Temperatura_PV AS Biorreactor_grande_avg_Temperatura_PV,\n",
    "    min_Temperatura_PV AS Biorreactor_grande_min_Temperatura_PV,\n",
    "    max_Temperatura_PV AS Biorreactor_grande_max_Temperatura_PV,\n",
    "    Turbidezmean AS IPC_Cultivos_Turbidezmean,\n",
    "    Turbidezstd AS IPC_Cultivos_Turbidezstd,\n",
    "    Turbidezmin AS IPC_Cultivos_Turbidezmin,\n",
    "    Turbidezmax AS IPC_Cultivos_Turbidezmax,\n",
    "    Viabilidadmean AS IPC_Cultivos_Viabilidadmean,\n",
    "    Viabilidadstd AS IPC_Cultivos_Viabilidadstd,\n",
    "    Viabilidadmin AS IPC_Cultivos_Viabilidadmin,\n",
    "    Viabilidadmax AS IPC_Cultivos_Viabilidadmax,\n",
    "    Glucosamean AS IPC_Cultivos_Glucosamean,\n",
    "    Glucosastd AS IPC_Cultivos_Glucosastd,\n",
    "    Glucosamin AS IPC_Cultivos_Glucosamin,\n",
    "    Glucosamax AS IPC_Cultivos_Glucosamax\n",
    "\n",
    "FROM \n",
    "    df_bio_metrics b\n",
    "LEFT JOIN \n",
    "    df_metricsIPC m\n",
    "ON \n",
    "    b.\"LOTE\" = m.\"Lote\"\n",
    "'''\n",
    "\n",
    "# Ejecutar la consulta\n",
    "df_cultivo_metrics = psql.sqldf(query, locals())\n",
    "\n",
    "display(df_cultivo_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d73952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta SQL para añadir la columna 'lote_abuelo'\n",
    "query = \"\"\"\n",
    "    SELECT df.*, \n",
    "           CASE \n",
    "               WHEN Orden = 3 THEN (\n",
    "                   SELECT LOTE_parental\n",
    "                   FROM df_cultivo_metrics AS parent\n",
    "                   WHERE parent.lote = df.LOTE_parental\n",
    "               )\n",
    "               ELSE NULL\n",
    "           END AS lote_abuelo\n",
    "    FROM df_cultivo_metrics df\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar la consulta\n",
    "df_cultivo_03 = psql.sqldf(query, locals())\n",
    "\n",
    "# Mostrar el resultado\n",
    "display(df_cultivo_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b1b65e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cultivo_03.to_excel(f'{path_structured}cultivo_final_total.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bab28d8",
   "metadata": {},
   "source": [
    "## 3.4 CULTIVO FINAL TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd90b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cultivotest_02 = path_cleansed + 'Fases producción_test_Cultivo final.xlsx'\n",
    "\n",
    "# Leemos los archivos Excel y guardamos el contenido en un DataFrame\n",
    "df_cultivotest_02 = pd.read_excel(path_cultivotest_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c2652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "    SELECT\n",
    "        l.*,\n",
    "        AVG(b.Agitation_PV) AS avg_Agitation_PV,\n",
    "        MIN(b.Agitation_PV) AS min_Agitation_PV,\n",
    "        MAX(b.Agitation_PV) AS max_Agitation_PV,\n",
    "\n",
    "        AVG(b.Air_Sparge_PV) AS avg_Air_Sparge_PV,\n",
    "        MIN(b.Air_Sparge_PV) AS min_Air_Sparge_PV,\n",
    "        MAX(b.Air_Sparge_PV) AS max_Air_Sparge_PV,\n",
    "\n",
    "        AVG(b.Biocontainer_Pressure_PV) AS avg_Biocontainer_Pressure_PV,\n",
    "        MIN(b.Biocontainer_Pressure_PV) AS min_Biocontainer_Pressure_PV,\n",
    "        MAX(b.Biocontainer_Pressure_PV) AS max_Biocontainer_Pressure_PV,\n",
    "\n",
    "        AVG(b.DO_1_PV) AS avg_DO_1_PV,\n",
    "        MIN(b.DO_1_PV) AS min_DO_1_PV,\n",
    "        MAX(b.DO_1_PV) AS max_DO_1_PV,\n",
    "\n",
    "        AVG(b.DO_2_PV) AS avg_DO_2_PV,\n",
    "        MIN(b.DO_2_PV) AS min_DO_2_PV,\n",
    "        MAX(b.DO_2_PV) AS max_DO_2_PV,\n",
    "\n",
    "        AVG(b.Gas_Overlay_PV) AS avg_Gas_Overlay_PV,\n",
    "        MIN(b.Gas_Overlay_PV) AS min_Gas_Overlay_PV,\n",
    "        MAX(b.Gas_Overlay_PV) AS max_Gas_Overlay_PV,\n",
    "\n",
    "        AVG(b.Load_Cell_Net_PV) AS avg_Load_Cell_Net_PV,\n",
    "        MIN(b.Load_Cell_Net_PV) AS min_Load_Cell_Net_PV,\n",
    "        MAX(b.Load_Cell_Net_PV) AS max_Load_Cell_Net_PV,\n",
    "\n",
    "        AVG(b.pH_1_PV) AS avg_pH_1_PV,\n",
    "        MIN(b.pH_1_PV) AS min_pH_1_PV,\n",
    "        MAX(b.pH_1_PV) AS max_pH_1_PV,\n",
    "\n",
    "        AVG(b.pH_2_PV) AS avg_pH_2_PV,\n",
    "        MIN(b.pH_2_PV) AS min_pH_2_PV,\n",
    "        MAX(b.pH_2_PV) AS max_pH_2_PV,\n",
    "\n",
    "        AVG(b.PUMP_1_PV) AS avg_PUMP_1_PV,\n",
    "        MIN(b.PUMP_1_PV) AS min_PUMP_1_PV,\n",
    "        MAX(b.PUMP_1_PV) AS max_PUMP_1_PV,\n",
    "\n",
    "        AVG(b.PUMP_1_TOTAL) AS avg_PUMP_1_TOTAL,\n",
    "        MIN(b.PUMP_1_TOTAL) AS min_PUMP_1_TOTAL,\n",
    "        MAX(b.PUMP_1_TOTAL) AS max_PUMP_1_TOTAL,\n",
    "\n",
    "        AVG(b.PUMP_2_PV) AS avg_PUMP_2_PV,\n",
    "        MIN(b.PUMP_2_PV) AS min_PUMP_2_PV,\n",
    "        MAX(b.PUMP_2_PV) AS max_PUMP_2_PV,\n",
    "\n",
    "        AVG(b.PUMP_2_TOTAL) AS avg_PUMP_2_TOTAL,\n",
    "        MIN(b.PUMP_2_TOTAL) AS min_PUMP_2_TOTAL,\n",
    "        MAX(b.PUMP_2_TOTAL) AS max_PUMP_2_TOTAL,\n",
    "\n",
    "        AVG(b.Single_Use_DO_PV) AS avg_Single_Use_DO_PV,\n",
    "        MIN(b.Single_Use_DO_PV) AS min_Single_Use_DO_PV,\n",
    "        MAX(b.Single_Use_DO_PV) AS max_Single_Use_DO_PV,\n",
    "\n",
    "        AVG(b.Single_Use_pH_PV) AS avg_Single_Use_pH_PV,\n",
    "        MIN(b.Single_Use_pH_PV) AS min_Single_Use_pH_PV,\n",
    "        MAX(b.Single_Use_pH_PV) AS max_Single_Use_pH_PV,\n",
    "\n",
    "        AVG(b.Temperatura_PV) AS avg_Temperatura_PV,\n",
    "        MIN(b.Temperatura_PV) AS min_Temperatura_PV,\n",
    "        MAX(b.Temperatura_PV) AS max_Temperatura_PV\n",
    "    FROM\n",
    "        df_cultivotest_02 l\n",
    "    LEFT JOIN\n",
    "        df_biograndes_02 b\n",
    "    ON\n",
    "        l.\"ID Bioreactor\" = b.Numero_Biorreactor\n",
    "        AND b.DateTime BETWEEN l.\"Fecha/hora inicio\" AND l.\"Fecha/hora fin\"\n",
    "    GROUP BY\n",
    "        l.\"LOTE\";\n",
    "'''\n",
    "\n",
    "# Ejecutar la consulta\n",
    "df_bio_metrics_test = psql.sqldf(query, locals())\n",
    "\n",
    "# Ver el resultado\n",
    "display(df_bio_metrics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "def105d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los campos de fecha de object a datetime\n",
    "df_bio_metrics_test['Fecha/hora inicio'] = pd.to_datetime(df_bio_metrics_test['Fecha/hora inicio'])\n",
    "df_bio_metrics_test['Fecha/hora fin'] = pd.to_datetime(df_bio_metrics_test['Fecha/hora fin'])\n",
    "\n",
    "# Calculamos la diferencia entre las fechas\n",
    "df_bio_metrics_test['horas_totales_cultivofinal'] = (df_bio_metrics_test['Fecha/hora fin'] - df_bio_metrics_test['Fecha/hora inicio']).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75c0e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREAMOS UN DATAFRAME CON MÉTRICAS DE LAS DISTINTAS COLUMNAS DE CINÉTICOS IPC SEGÚN EL LOTE (MEDIA, MIN,...)\n",
    "df_metricsIPC_test = df_cultivoIPC_02.groupby('Lote').agg({\n",
    "    'Turbidez': ['mean', 'std', 'min', 'max'],\n",
    "    'Viabilidad': ['mean', 'std', 'min', 'max'],\n",
    "    'Glucosa': ['mean', 'std', 'min', 'max']\n",
    "}).reset_index()\n",
    "df_metricsIPC_test.columns = [''.join(col).strip() for col in df_metricsIPC_test.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fd9565",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT \n",
    "    b.LOTE,\n",
    "    `Orden en el encadenado` AS Orden,\n",
    "    `LOTE parental` AS LOTE_parental,\n",
    "    `ID Bioreactor` AS ID_Bioreactor,\n",
    "    horas_totales_cultivofinal,\n",
    "    `Volumen de inóculo utilizado` AS Volumen_inoculo_utilizado,\n",
    "    `Turbidez inicio cultivo` AS Turbidez_inicio_cultivo,\n",
    "    `Turbidez fin cultivo` AS Turbidez_fin_cultivo,\n",
    "    `Viabilidad final cultivo` AS Viabilidad_final_cultivo,\n",
    "    `ID Centrífuga` AS ID_Centrifuga,\n",
    "    `Centrifugación 1 turbidez` AS Centrifugacion_1_turbidez,\n",
    "    `Centrifugación 2 turbidez` AS Centrifugacion_2_turbidez,\n",
    "    `Producto 1` AS Producto_1,\n",
    "    avg_Agitation_PV AS Biorreactor_grande_avg_Agitation_PV,\n",
    "    min_Agitation_PV AS Biorreactor_grande_min_Agitation_PV,\n",
    "    max_Agitation_PV AS Biorreactor_grande_max_Agitation_PV,\n",
    "    avg_Air_Sparge_PV AS Biorreactor_grande_avg_Air_Sparge_PV,\n",
    "    min_Air_Sparge_PV AS Biorreactor_grande_min_Air_Sparge_PV,\n",
    "    max_Air_Sparge_PV AS Biorreactor_grande_max_Air_Sparge_PV,\n",
    "    avg_Biocontainer_Pressure_PV AS Biorreactor_grande_avg_Biocontainer_Pressure_PV,\n",
    "    min_Biocontainer_Pressure_PV AS Biorreactor_grande_min_Biocontainer_Pressure_PV,\n",
    "    max_Biocontainer_Pressure_PV AS Biorreactor_grande_max_Biocontainer_Pressure_PV,\n",
    "    avg_DO_1_PV AS Biorreactor_grande_avg_DO_1_PV,\n",
    "    min_DO_1_PV AS Biorreactor_grande_min_DO_1_PV,\n",
    "    max_DO_1_PV AS Biorreactor_grande_max_DO_1_PV,\n",
    "    avg_DO_2_PV AS Biorreactor_grande_avg_DO_2_PV,\n",
    "    min_DO_2_PV AS Biorreactor_grande_min_DO_2_PV,\n",
    "    max_DO_2_PV AS Biorreactor_grande_max_DO_2_PV,\n",
    "    avg_Gas_Overlay_PV AS Biorreactor_grande_avg_Gas_Overlay_PV,\n",
    "    min_Gas_Overlay_PV AS Biorreactor_grande_min_Gas_Overlay_PV,\n",
    "    max_Gas_Overlay_PV AS Biorreactor_grande_max_Gas_Overlay_PV,\n",
    "    avg_Load_Cell_Net_PV AS Biorreactor_grande_avg_Load_Cell_Net_PV,\n",
    "    min_Load_Cell_Net_PV AS Biorreactor_grande_min_Load_Cell_Net_PV,\n",
    "    max_Load_Cell_Net_PV AS Biorreactor_grande_max_Load_Cell_Net_PV,\n",
    "    avg_pH_1_PV AS Biorreactor_grande_avg_pH_1_PV,\n",
    "    min_pH_1_PV AS Biorreactor_grande_min_pH_1_PV,\n",
    "    max_pH_1_PV AS Biorreactor_grande_max_pH_1_PV,\n",
    "    avg_pH_2_PV AS Biorreactor_grande_avg_pH_2_PV,\n",
    "    min_pH_2_PV AS Biorreactor_grande_min_pH_2_PV,\n",
    "    max_pH_2_PV AS Biorreactor_grande_max_pH_2_PV,\n",
    "    avg_PUMP_1_PV AS Biorreactor_grande_avg_PUMP_1_PV,\n",
    "    min_PUMP_1_PV AS Biorreactor_grande_min_PUMP_1_PV,\n",
    "    max_PUMP_1_PV AS Biorreactor_grande_max_PUMP_1_PV,\n",
    "    avg_PUMP_1_TOTAL AS Biorreactor_grande_avg_PUMP_1_TOTAL,\n",
    "    min_PUMP_1_TOTAL AS Biorreactor_grande_min_PUMP_1_TOTAL,\n",
    "    max_PUMP_1_TOTAL AS Biorreactor_grande_max_PUMP_1_TOTAL,\n",
    "    avg_PUMP_2_PV AS Biorreactor_grande_avg_PUMP_2_PV,\n",
    "    min_PUMP_2_PV AS Biorreactor_grande_min_PUMP_2_PV,\n",
    "    max_PUMP_2_PV AS Biorreactor_grande_max_PUMP_2_PV,\n",
    "    avg_PUMP_2_TOTAL AS Biorreactor_grande_avg_PUMP_2_TOTAL,\n",
    "    min_PUMP_2_TOTAL AS Biorreactor_grande_min_PUMP_2_TOTAL,\n",
    "    max_PUMP_2_TOTAL AS Biorreactor_grande_max_PUMP_2_TOTAL,\n",
    "    avg_Single_Use_DO_PV AS Biorreactor_grande_avg_Single_Use_DO_PV,\n",
    "    min_Single_Use_DO_PV AS Biorreactor_grande_min_Single_Use_DO_PV,\n",
    "    max_Single_Use_DO_PV AS Biorreactor_grande_max_Single_Use_DO_PV,\n",
    "    avg_Single_Use_pH_PV AS Biorreactor_grande_avg_Single_Use_pH_PV,\n",
    "    min_Single_Use_pH_PV AS Biorreactor_grande_min_Single_Use_pH_PV,\n",
    "    max_Single_Use_pH_PV AS Biorreactor_grande_max_Single_Use_pH_PV,\n",
    "    avg_Temperatura_PV AS Biorreactor_grande_avg_Temperatura_PV,\n",
    "    min_Temperatura_PV AS Biorreactor_grande_min_Temperatura_PV,\n",
    "    max_Temperatura_PV AS Biorreactor_grande_max_Temperatura_PV,\n",
    "    Turbidezmean AS IPC_Cultivos_Turbidezmean,\n",
    "    Turbidezstd AS IPC_Cultivos_Turbidezstd,\n",
    "    Turbidezmin AS IPC_Cultivos_Turbidezmin,\n",
    "    Turbidezmax AS IPC_Cultivos_Turbidezmax,\n",
    "    Viabilidadmean AS IPC_Cultivos_Viabilidadmean,\n",
    "    Viabilidadstd AS IPC_Cultivos_Viabilidadstd,\n",
    "    Viabilidadmin AS IPC_Cultivos_Viabilidadmin,\n",
    "    Viabilidadmax AS IPC_Cultivos_Viabilidadmax,\n",
    "    Glucosamean AS IPC_Cultivos_Glucosamean,\n",
    "    Glucosastd AS IPC_Cultivos_Glucosastd,\n",
    "    Glucosamin AS IPC_Cultivos_Glucosamin,\n",
    "    Glucosamax AS IPC_Cultivos_Glucosamax\n",
    "\n",
    "FROM \n",
    "    df_bio_metrics_test b\n",
    "LEFT JOIN \n",
    "    df_metricsIPC_test m\n",
    "ON \n",
    "    b.\"LOTE\" = m.\"Lote\"\n",
    "'''\n",
    "\n",
    "# Ejecutar la consulta\n",
    "df_cultivo_metrics_test = psql.sqldf(query, locals())\n",
    "\n",
    "display(df_cultivo_metrics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e07c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta SQL para añadir la columna 'lote_abuelo'\n",
    "query = \"\"\"\n",
    "    SELECT df.*, \n",
    "           CASE \n",
    "               WHEN Orden = 3 THEN (\n",
    "                   SELECT LOTE_parental\n",
    "                   FROM df_cultivo_metrics_test AS parent\n",
    "                   WHERE parent.lote = df.LOTE_parental\n",
    "               )\n",
    "               ELSE NULL\n",
    "           END AS lote_abuelo\n",
    "    FROM df_cultivo_metrics_test df\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar la consulta\n",
    "df_cultivo_test_03 = psql.sqldf(query, locals())\n",
    "\n",
    "# Mostrar el resultado\n",
    "display(df_cultivo_test_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c4a5294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cultivo_test_03.to_excel(f'{path_structured}cultivo_final_test_total.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae67a60",
   "metadata": {},
   "source": [
    "## 3.5 CENTRIFUGACIÓN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fb1b8e",
   "metadata": {},
   "source": [
    "### Notas sobre los resultados las tablas creadas\n",
    "\n",
    "- No hay datos sobre el Lote 0 en la tabla *CineticosIPC_Centrifugacion.xlsx*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70f3a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos los archivos Excel y guardamos el contenido en un DataFrame\n",
    "path_cent_02 = path_cleansed + 'Centrifugacion.xlsx'\n",
    "path_OF_02 = path_cleansed + 'OF_123456.xlsx'\n",
    "path_centrifugadoras_02 = path_cleansed + 'centrifugadoras.xlsx'\n",
    "path_centIPC_02 = path_cleansed + 'CineticosIPC_Centrifugacion.xlsx'\n",
    "\n",
    "df_cent_02 = pd.read_excel(path_cent_02)\n",
    "df_OF_02 = pd.read_excel(path_OF_02)\n",
    "df_centrifugadoras_02 = pd.read_excel(path_centrifugadoras_02)\n",
    "df_centIPC_02 = pd.read_excel(path_centIPC_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3411d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivotamos la tabla Centrifugacion usando 'Orden' como clave para reorganizar las operaciones y sus correspondientes valores de 'DATETIME'\n",
    "df_pivoted_cent= df_cent_02.pivot_table(index=['Orden', 'EQUIPO'], columns='Operación', values='DATETIME', aggfunc='first').reset_index()\n",
    "display(df_pivoted_cent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b440e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gracias al LEFT JOIN sólo nos quedamos con los lotes que aparecen en la tabla 0F_123456 (no hay que tenerlos en cuenta)\n",
    "consulta = \"\"\"\n",
    "    SELECT \n",
    "    Lote,\n",
    "    EQUIPO AS ID_centrifuga,\n",
    "    `Centrifugació 1 ini` AS Inicio_Centrifugacion_1,\n",
    "    `Centrifugació 1 fi` AS Fin_Centrifugacion_1,\n",
    "    `Centrifugació 2 ini` AS Inicio_Centrifugacion_2,\n",
    "    `Centrifugació 2 fi` AS Fin_Centrifugacion_2\n",
    "\n",
    "\n",
    "    FROM df_OF_02 OF \n",
    "    LEFT JOIN df_pivoted_cent cent\n",
    "    ON OF.OF = cent.Orden\n",
    "    \"\"\"\n",
    "\n",
    "# Ejecutamos la consulta y generamos un dataframe\n",
    "df_OF_cent = psql.sqldf(consulta, locals())\n",
    "display(df_OF_cent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f618728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos -por lote- la media, el valor mínimo y el máximo de cada medida de la tabla CineticosIPC_Centrifugacion \n",
    "# en cada intervalo de tiempo de ambas centrifugaciones\n",
    "consulta = '''\n",
    "    SELECT\n",
    "        OFc.Lote,\n",
    "        ID_centrifuga,\n",
    "\n",
    "        -- Métricas centrifugación 1 --\n",
    "\n",
    "        Inicio_Centrifugacion_1,\n",
    "        Fin_Centrifugacion_1,\n",
    "\n",
    "        AVG(cd1.velocidad_separación) AS avg_velocidad_sep_1,\n",
    "        MIN(cd1.velocidad_separación) AS min_velocidad_sep_1,\n",
    "        MAX(cd1.velocidad_separación) AS max_velocidad_sep_1,\n",
    "\n",
    "        AVG(cd1.presion_agua) AS avg_presion_agua_1,\n",
    "        MIN(cd1.presion_agua) AS min_presion_agua_1,\n",
    "        MAX(cd1.presion_agua) AS max_presion_agua_1,\n",
    "        \n",
    "        AVG(cd1.contrapresion) AS avg_contrapresion_1,\n",
    "        MIN(cd1.contrapresion) AS min_contrapresion_1,\n",
    "        MAX(cd1.contrapresion) AS max_contrapresion_1,\n",
    "\n",
    "        AVG(cd1.caudal) AS avg_caudal_1,\n",
    "        MIN(cd1.caudal) AS min_caudal_1,\n",
    "        MAX(cd1.caudal) AS max_caudal_1,\n",
    "\n",
    "        AVG(cd1.apertura_valvula_agua) AS avg_apertura_valvula_agua_1,\n",
    "        MIN(cd1.apertura_valvula_agua) AS min_apertura_valvula_agua_1,\n",
    "        MAX(cd1.apertura_valvula_agua) AS max_apertura_valvula_agua_1,\n",
    "\n",
    "        AVG(cd1.descargas_totales) AS avg_descargas_totales_1,\n",
    "        MIN(cd1.descargas_totales) AS min_descargas_totales_1,\n",
    "        MAX(cd1.descargas_totales) AS max_descargas_totales_1,\n",
    "\n",
    "        AVG(cd1.`descargas parciales`) AS avg_descargas_parciales_1,\n",
    "        MIN(cd1.`descargas parciales`) AS min_descargas_parciales_1,\n",
    "        MAX(cd1.`descargas parciales`) AS max_descargas_parciales_1,\n",
    "\n",
    "        -- Métricas centrifugación 2 --\n",
    "\n",
    "        Inicio_Centrifugacion_2,\n",
    "        Fin_Centrifugacion_2,\n",
    "\n",
    "        AVG(cd2.velocidad_separación) AS avg_velocidad_sep_2,\n",
    "        MIN(cd2.velocidad_separación) AS min_velocidad_sep_2,\n",
    "        MAX(cd2.velocidad_separación) AS max_velocidad_sep_2,\n",
    "\n",
    "        AVG(cd2.presion_agua) AS avg_presion_agua_2,\n",
    "        MIN(cd2.presion_agua) AS min_presion_agua_2,\n",
    "        MAX(cd2.presion_agua) AS max_presion_agua_2,\n",
    "        \n",
    "        AVG(cd2.contrapresion) AS avg_contrapresion_2,\n",
    "        MIN(cd2.contrapresion) AS min_contrapresion_2,\n",
    "        MAX(cd2.contrapresion) AS max_contrapresion_2,\n",
    "\n",
    "        AVG(cd2.caudal) AS avg_caudal_2,\n",
    "        MIN(cd2.caudal) AS min_caudal_2,\n",
    "        MAX(cd2.caudal) AS max_caudal_2,\n",
    "\n",
    "        AVG(cd2.apertura_valvula_agua) AS avg_apertura_valvula_agua_2,\n",
    "        MIN(cd2.apertura_valvula_agua) AS min_apertura_valvula_agua_2,\n",
    "        MAX(cd2.apertura_valvula_agua) AS max_apertura_valvula_agua_2,\n",
    "\n",
    "        AVG(cd2.descargas_totales) AS avg_descargas_totales_2,\n",
    "        MIN(cd2.descargas_totales) AS min_descargas_totales_2,\n",
    "        MAX(cd2.descargas_totales) AS max_descargas_totales_2,\n",
    "\n",
    "        AVG(cd2.`descargas parciales`) AS avg_descargas_parciales_2,\n",
    "        MIN(cd2.`descargas parciales`) AS min_descargas_parciales_2,\n",
    "        MAX(cd2.`descargas parciales`) AS max_descargas_parciales_2\n",
    "\n",
    "    FROM\n",
    "        df_OF_cent OFc\n",
    "\n",
    "    LEFT JOIN\n",
    "        df_centrifugadoras_02 cd1\n",
    "    ON\n",
    "        OFc.ID_centrifuga = cd1.EQUIPO\n",
    "        AND cd1.DateTime BETWEEN OFc.Inicio_Centrifugacion_1 AND OFc.Fin_Centrifugacion_1\n",
    "\n",
    "    LEFT JOIN\n",
    "        df_centrifugadoras_02 cd2\n",
    "    ON\n",
    "        OFc.ID_centrifuga = cd2.EQUIPO\n",
    "        AND cd2.DateTime BETWEEN OFc.Inicio_Centrifugacion_2 AND OFc.Fin_Centrifugacion_2\n",
    "\n",
    "    GROUP BY\n",
    "        OFc.Lote;\n",
    "'''\n",
    "\n",
    "# Ejecutamos la consulta y generamos un dataframe\n",
    "df_metrics_cent = psql.sqldf(consulta, locals())\n",
    "display(df_metrics_cent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57268cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los campos de fecha de object a datetime\n",
    "df_metrics_cent['Inicio_Centrifugacion_1'] = pd.to_datetime(df_metrics_cent['Inicio_Centrifugacion_1'])\n",
    "df_metrics_cent['Fin_Centrifugacion_1'] = pd.to_datetime(df_metrics_cent['Fin_Centrifugacion_1'])\n",
    "df_metrics_cent['Inicio_Centrifugacion_2'] = pd.to_datetime(df_metrics_cent['Inicio_Centrifugacion_2'])\n",
    "df_metrics_cent['Fin_Centrifugacion_2'] = pd.to_datetime(df_metrics_cent['Fin_Centrifugacion_2'])\n",
    "\n",
    "# Calculamos la diferencia entre las fechas\n",
    "df_metrics_cent['tiempo_centrifugacion_1'] = (df_metrics_cent['Fin_Centrifugacion_1'] - df_metrics_cent['Inicio_Centrifugacion_1']).dt.total_seconds() / 3600\n",
    "df_metrics_cent['tiempo_centrifugacion_2'] = (df_metrics_cent['Fin_Centrifugacion_2'] - df_metrics_cent['Inicio_Centrifugacion_2']).dt.total_seconds() / 3600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef2d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos los lotes de CineticosIPC_Centrifugacion que no se encuentrene en OF_123456 (no hay que tenerlos en cuenta)\n",
    "consulta = '''\n",
    "    SELECT\n",
    "        OF.Lote,\n",
    "        Centrífuga,\n",
    "        `Centrifugada (1 o 2)`,\n",
    "        `Volumen centrifugado (L)`,\n",
    "        Turbidez\n",
    "\n",
    "    FROM\n",
    "        df_OF_02 OF\n",
    "\n",
    "    LEFT JOIN \n",
    "        df_centIPC_02 cIPC\n",
    "    ON \n",
    "        OF.Lote = cIPC.Lote\n",
    "\n",
    "'''\n",
    "\n",
    "# Ejecutamos la consulta y generamos un dataframe\n",
    "df_OF_centIPC = psql.sqldf(consulta, locals())\n",
    "display(df_OF_centIPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64285eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivotamos la tabla CineticosIPC_Centrifugacion (habiendo eliminado los lotes que no aparecen en OF_123456) \n",
    "# usando Lote y Centrífuga como claves para reorganizar las operaciones y sus correspondientes valores de Turbidez \n",
    "df_pivoted_centIPC= df_OF_centIPC.pivot_table(index=['Lote', 'Centrífuga'], columns=['Centrifugada (1 o 2)', 'Volumen centrifugado (L)'], values='Turbidez', aggfunc='first').reset_index()\n",
    "\n",
    "# Renombramos los nombres de las columnas\n",
    "df_pivoted_centIPC.columns = ['Lote', 'Centrífuga', 'Turbidez_1_100', 'Turbidez_1_200','Turbidez_1_400','Turbidez_1_600','Turbidez_1_800','Turbidez_1_1000','Turbidez_1_1200','Turbidez_1_1400','Turbidez_1_1600','Turbidez_1_1800','Turbidez_1_2000','Turbidez_2_100','Turbidez_2_200','Turbidez_2_300','Turbidez_2_400',]\n",
    "display(df_pivoted_centIPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454c8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntamos CineticosIPC_Centrifugacion pivotada con el dataframe df_metrics_cent \n",
    "consulta = '''\n",
    "    SELECT\n",
    "        mc.Lote,\n",
    "        ID_centrifuga,\n",
    "\n",
    "        -- Centrifugacion 1 --\n",
    "        tiempo_centrifugacion_1,\n",
    "        avg_velocidad_sep_1,\n",
    "        min_velocidad_sep_1,\n",
    "        max_velocidad_sep_1,\n",
    "        avg_presion_agua_1,\n",
    "        min_presion_agua_1,\n",
    "        max_presion_agua_1,\n",
    "        avg_contrapresion_1,\n",
    "        min_contrapresion_1,\n",
    "        max_contrapresion_1,\n",
    "        avg_caudal_1,\n",
    "        min_caudal_1,\n",
    "        max_caudal_1,\n",
    "        avg_apertura_valvula_agua_1,\n",
    "        min_apertura_valvula_agua_1,\n",
    "        max_apertura_valvula_agua_1,\n",
    "        avg_descargas_totales_1,\n",
    "        min_descargas_totales_1,\n",
    "        max_descargas_totales_1,\n",
    "        avg_descargas_parciales_1,\n",
    "        min_descargas_parciales_1,\n",
    "        max_descargas_parciales_1,\n",
    "        Turbidez_1_100,\n",
    "        Turbidez_1_200,\n",
    "        Turbidez_1_400,\n",
    "        Turbidez_1_600,\n",
    "        Turbidez_1_800,\n",
    "        Turbidez_1_1000,\n",
    "        Turbidez_1_1200,\n",
    "        Turbidez_1_1400,\n",
    "        Turbidez_1_1600,\n",
    "        Turbidez_1_1800,\n",
    "        Turbidez_1_2000,\n",
    "\n",
    "        -- Centrifugacion 2 --\n",
    "        tiempo_centrifugacion_2,\n",
    "        avg_velocidad_sep_2,\n",
    "        min_velocidad_sep_2,\n",
    "        max_velocidad_sep_2,\n",
    "        avg_presion_agua_2,\n",
    "        min_presion_agua_2,\n",
    "        max_presion_agua_2,\n",
    "        avg_contrapresion_2,\n",
    "        min_contrapresion_2,\n",
    "        max_contrapresion_2,\n",
    "        avg_caudal_2,\n",
    "        min_caudal_2,\n",
    "        max_caudal_2,\n",
    "        avg_apertura_valvula_agua_2,\n",
    "        min_apertura_valvula_agua_2,\n",
    "        max_apertura_valvula_agua_2,\n",
    "        avg_descargas_totales_2,\n",
    "        min_descargas_totales_2,\n",
    "        max_descargas_totales_2,\n",
    "        avg_descargas_parciales_2,\n",
    "        min_descargas_parciales_2,\n",
    "        max_descargas_parciales_2,\n",
    "        Turbidez_2_100,\n",
    "        Turbidez_2_200,\n",
    "        Turbidez_2_300,\n",
    "        Turbidez_2_400\n",
    "\n",
    "\n",
    "    FROM\n",
    "        df_metrics_cent mc\n",
    "\n",
    "    LEFT JOIN \n",
    "        df_pivoted_centIPC cIPC\n",
    "    ON \n",
    "        mc.Lote = cIPC.Lote\n",
    "\n",
    "'''\n",
    "# Ejecutar la consulta\n",
    "df_cent_03 = psql.sqldf(consulta, locals())\n",
    "display(df_cent_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce6ef950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el resultado en un archivo Excel\n",
    "df_cent_03.to_excel(f'{path_structured}centrifugacion_total.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fd5acb",
   "metadata": {},
   "source": [
    "## 3.6 MATERIAS PRIMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd5744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mp_02 = path_cleansed + 'materias_primas.xlsx'\n",
    "\n",
    "df_mp_02 = pd.read_excel(path_mp_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7aa180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivotamos la tabla Centrifugacion usando 'Orden' como clave para reorganizar las operaciones y sus correspondientes valores de 'DATETIME'\n",
    "df_mp_03= df_mp_02.pivot_table(index='Lote', columns='Material', values='Qty', aggfunc='sum').reset_index()\n",
    "df_mp_03.columns = ['Lote', 'qty_01', 'qty_02', 'qty_03', 'qty_04', 'qty_05', 'qty_06', 'qty_07', 'qty_08', 'qty_09', 'qty_10', 'qty_11', 'qty_12', 'qty_13']\n",
    "display(df_mp_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab9a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mp_03.to_excel(f'{path_structured}materias_primas_total.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9982d150",
   "metadata": {},
   "source": [
    "# 4. ANALYTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "051c12f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandasql as psql\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c737c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_structured = 'C:\\\\Users\\\\anton\\\\OneDrive\\\\Documentos\\\\GitHub\\\\UniversityHack2024\\\\data\\\\03_structured\\\\'\n",
    "path_analytics = 'C:\\\\Users\\\\anton\\\\OneDrive\\\\Documentos\\\\GitHub\\\\UniversityHack2024\\\\data\\\\04_analytics\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0579b",
   "metadata": {},
   "source": [
    "## 4.1 TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e816545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_materias_03 = path_structured + 'materias_primas_total.xlsx'\n",
    "path_preinoculo_03 = path_structured + 'preinoculo_total.xlsx'\n",
    "path_inoculo_03 = path_structured + 'inoculo_total.xlsx'\n",
    "path_cultivo_03 = path_structured + 'cultivo_final_total.xlsx'\n",
    "path_cent_03 = path_structured + 'centrifugacion_total.xlsx'\n",
    "\n",
    "\n",
    "# Leer el archivo Excel y guardar el contenido en un DataFrame\n",
    "df_materiales_03 = pd.read_excel(path_materias_03)\n",
    "df_preinoculo_03 = pd.read_excel(path_preinoculo_03)\n",
    "df_inoculo_03 = pd.read_excel(path_inoculo_03)\n",
    "df_cultivo_03 = pd.read_excel(path_cultivo_03)\n",
    "df_cent_03 = pd.read_excel(path_cent_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "consulta = ''' \n",
    "    SELECT\n",
    "    *\n",
    "    FROM \n",
    "        df_cultivo_03 cu\n",
    "\n",
    "    LEFT JOIN \n",
    "        df_materiales_03 m\n",
    "    ON \n",
    "        CAST(m.Lote AS TEXT) = CAST(cu.LOTE AS TEXT)\n",
    "\n",
    "    LEFT JOIN \n",
    "        df_preinoculo_03 pre\n",
    "    ON\n",
    "        pre.LOTE = CAST(COALESCE(cu.lote_abuelo, cu.`LOTE parental`, cu.LOTE) AS TEXT)\n",
    "\n",
    "    LEFT JOIN\n",
    "        df_inoculo_03 ino\n",
    "    ON\n",
    "        ino.LOTE = CAST(COALESCE(cu.lote_abuelo, cu.`LOTE parental`, cu.LOTE) AS TEXT)\n",
    "\n",
    "    LEFT JOIN\n",
    "        df_cent_03 cent\n",
    "    ON\n",
    "        CAST(cent.Lote AS TEXT) = CAST(cu.LOTE AS TEXT)\n",
    "\n",
    "'''\n",
    "# Ejecutamos la consulta y generamos un dataframe\n",
    "df_train = psql.sqldf(consulta, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "005959e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el resultado en un archivo Excel\n",
    "df_train.to_excel(f'{path_analytics}train.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6aa9a9",
   "metadata": {},
   "source": [
    "## 4.2 TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07b29a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cultivo_test_03 = path_structured + 'cultivo_final_test_total.xlsx'\n",
    "\n",
    "# Leer el archivo Excel y guardar el contenido en un DataFrame\n",
    "df_cultivo_test_03 = pd.read_excel(path_cultivo_test_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee99aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "consulta = ''' \n",
    "    SELECT\n",
    "    *\n",
    "    FROM \n",
    "        df_cultivo_test_03 cu\n",
    "\n",
    "    LEFT JOIN \n",
    "        df_materiales_03 m\n",
    "    ON \n",
    "        CAST(m.Lote AS TEXT) = CAST(cu.LOTE AS TEXT)\n",
    "\n",
    "    LEFT JOIN \n",
    "        df_preinoculo_03 pre\n",
    "    ON\n",
    "        pre.LOTE = CAST(COALESCE(cu.lote_abuelo, cu.LOTE_parental, cu.LOTE) AS TEXT)\n",
    "\n",
    "    LEFT JOIN\n",
    "        df_inoculo_03 ino\n",
    "    ON\n",
    "        ino.LOTE = CAST(COALESCE(cu.lote_abuelo, cu.LOTE_parental, cu.LOTE) AS TEXT)\n",
    "\n",
    "    LEFT JOIN\n",
    "        df_cent_03 cent\n",
    "    ON\n",
    "        CAST(cent.Lote AS TEXT) = CAST(cu.LOTE AS TEXT)\n",
    "\n",
    "'''\n",
    "# Ejecutamos la consulta y generamos un dataframe\n",
    "df_test = psql.sqldf(consulta, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "426dd0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el resultado en un archivo Excel\n",
    "df_test.to_excel(f'{path_analytics}test.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfad0da4",
   "metadata": {},
   "source": [
    "## 4.3 PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6acca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel(f'{path_analytics}train.xlsx') #este train es de la carpeta model_input\n",
    "y = train.PRODUCTO_1\n",
    "X = train.drop('PRODUCTO_1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de53ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#probamos con diversas combinaciones de hiperparametros para buscar los mejores mediante cross validation\n",
    "#con los hiperparametros q mejores resultados obtengamos, reentrenaremos el modelo con todos los datos\n",
    "\n",
    "metrics = {}\n",
    "for n_estimators in [5, 10, 25, 50, 100, 250, 500]:\n",
    "    for max_depth in [2, 3, 5, 7]:\n",
    "        for eta in [0.05, 0.1, 0.2, 0.5]:\n",
    "            model = XGBRegressor(n_estimators=n_estimators, max_depth=max_depth, learning_rate=eta)\n",
    "            rmse_scores = - cross_val_score(model, X, y, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "            metrics[f'xgb_{n_estimators}_{max_depth}_{eta}'] = {\n",
    "                'RMSE_1': rmse_scores[0],\n",
    "                'RMSE_2': rmse_scores[1],\n",
    "                'RMSE_3': rmse_scores[2],\n",
    "                'RMSE_4': rmse_scores[3],\n",
    "                'RMSE_5': rmse_scores[4],\n",
    "                'MEAN_RMSE': rmse_scores.mean()\n",
    "            }\n",
    "\n",
    "metrics_xgb = pd.DataFrame.from_dict(metrics, orient='index',columns=['RMSE_1', 'RMSE_2', 'RMSE_3', 'RMSE_4', 'RMSE_5', 'MEAN_RMSE'])\n",
    "metrics_xgb.sort_values(by='MEAN_RMSE') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5683aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reentrenamos el modelo con los mejores hiperparametros\n",
    "time1 = time.time()\n",
    "xgb = XGBRegressor(n_estimators=250, max_depth=3, learning_rate=0.05, random_state=73).fit(X, y)\n",
    "time2 = time.time() - time1\n",
    "preds = xgb.predict(X)\n",
    "rmse = root_mean_squared_error(y, preds)\n",
    "print('Tiempo de ejecución: '+str(time2)+' segundos. \\nRMSE sobre el train: '+str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51865af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(xgb, 'C:\\\\Users\\\\anton\\\\OneDrive\\\\Documentos\\\\GitHub\\\\UniversityHack2024\\\\01_Data\\\\06_model_output\\\\models\\\\xgboost.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fd8fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot para observar cómo se comportan las estimaciones sobre los valores reales (ejecútalo para que se vea)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(y, preds)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], '--r', lw=2)\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Predicciones vs valores reales XGBoost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1436c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leemos el dataset de test\n",
    "test = pd.read_excel('05_model_input/test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f8d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generamos las predicciones para el dataset de respuesta\n",
    "pred = xgb.predict(test)\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
